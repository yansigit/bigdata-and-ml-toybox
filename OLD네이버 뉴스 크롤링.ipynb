{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://news.naver.com/\"\n",
    "\n",
    "ages = (10, 20, 30, 40, 50, 60)\n",
    "news = {'연령': [], '제목': [], '기사 내용 요약본': [], '신문사': [], '조회수': [], '원문 url': []}\n",
    "\n",
    "html = requests.get(url, headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36'})\n",
    "soup = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "presslist = soup.select(\"#_rankingList0 .list_press\")\n",
    "titlelist = soup.select(\"#_rankingList0 .list_tit\")\n",
    "\n",
    "tmp = []\n",
    "for i in range(len(titlelist)):\n",
    "    tmp.append([presslist[i].text, titlelist[i].text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['연합뉴스TV', '입양 2시간 만에 진돗개 모녀 도살…70대 구속'], ['중앙일보', \"라이터 갖다 대자 불 '화르륵'…중국 한 마을의 이상한 수 …\"], ['조선일보', '미친 전세에 지친 무주택자, 노·도·강부터 샀다'], ['연합뉴스', '노량진발 확진자 1명 교원 임용시험 응시…형평성 논란 불가 …'], ['시사IN', '‘균형 잡힌’ 방역이라야 지속가능하다']]\n"
     ]
    }
   ],
   "source": [
    "# 3-1\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'경향신문': '032', '국민일보': '005', '동아일보': '020', '문화일보': '021', '서울신문': '081', '세계일보': '022', '조선일보': '023', '중앙일보': '025', '한겨레': '028', '한국일보': '469', '뉴스1': '421', '뉴시스': '003', '연합뉴스': '001', '연합뉴스TV': '422', '채널A': '449', '한국경제TV': '215', 'JTBC': '437', 'KBS': '056', 'MBC': '214', 'MBN': '057', 'SBS': '055', 'SBS CNBC': '374', 'TV조선': '448', 'YTN': '052', '매일경제': '009', '머니투데이': '008', '서울경제': '011', '아시아경제': '277', '이데일리': '018', '조선비즈': '366', '조세일보': '123', '파이낸셜뉴스': '014', '한국경제': '015', '헤럴드경제': '016', '노컷뉴스': '079', '더팩트': '629', '데일리안': '119', '머니S': '417', '미디어오늘': '006', '아이뉴스24': '031', '오마이뉴스': '047', '프레시안': '002', '디지털데일리': '138', '디지털타임스': '029', '블로터': '293', '전자신문': '030', 'ZDNet Korea': '092', '레이디경향': '145', '매경이코노미': '024', '시사IN': '308', '시사저널': '586', '신동아': '262', '월간 산': '094', '이코노미스트': '243', '주간경향': '033', '주간동아': '037', '주간조선': '053', '중앙SUNDAY': '353', '한겨레21': '036', '한경비즈니스': '050', '기자협회보': '127', '뉴스타파': '607', '동아사이언스': '584', '여성신문': '310', '일다': '007', '코리아중앙데일리': '640', '코리아헤럴드': '044', '코메디닷컴': '296', '헬스조선': '346', '강원일보': '087', '매일신문': '088', '부산일보': '082', '신화사 연합뉴스': '348', 'AP연합뉴스': '077', 'EPA연합뉴스': '091'}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://news.naver.com/main/officeList.nhn\"\n",
    "# 크롤링 차단하고 있으므로 User-Agent 지정하여 우회\n",
    "html = requests.get(url, headers={\"User-Agent\" : \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "# 신문 제공사 딕셔너리\n",
    "# 신문사이름: 신문사번호\n",
    "newspapers = {}\n",
    "\n",
    "# css selector 이용하여 파싱\n",
    "for ele in soup.select('ul.group_list a'):\n",
    "    newspapers[ele.text] = (ele['href'].split('&oid=')[1])\n",
    "\n",
    "# 파라미터 붙어서 수동할당\n",
    "newspapers['연합뉴스'] = '001'\n",
    "\n",
    "print(newspapers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 출력된 리스트 중 하나 산택\n",
    "# company = '동아일보'\n",
    "\n",
    "news = {'신문사': [], '제목': [], 'link': []}\n",
    "\n",
    "def startparse(company):\n",
    "    # 오늘날짜 선택\n",
    "    date = datetime.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "    # 정치, 경제, 사회, 생활/문화, 세계, IT/과학, 오피니언 중 선택\n",
    "    # subject = '정치'\n",
    "\n",
    "    # 분류 딕셔너리\n",
    "    sids = {'정치': '100', '경제': '101', '사회': '102', '생활/문화': '103', '세계': '104', 'IT/과학': '105', '오피니언': '110'}\n",
    "\n",
    "    # 신문사 넘버\n",
    "    company_num = newspapers[company]\n",
    "\n",
    "    # 분야 번호\n",
    "    # sid = sids[subject]\n",
    "\n",
    "    # dataFrame dictionary\n",
    "    # news = {'신문사': [], '제목': [], 'link': []}\n",
    "\n",
    "    for sid in sids:\n",
    "        # 뉴스 페이지들 끝 번호 알아내기\n",
    "        url = \"https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1={}&mid=sec&oid={}&date={}&page=9999\".format(sids[sid], company_num, date)\n",
    "        html = requests.get(url, headers={\"User-Agent\" : \"Mozilla/5.0\"})\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "        pages = soup.select('div.paging strong')\n",
    "\n",
    "        lastpage = int(pages[-1].text)\n",
    "\n",
    "        # 각 페이지마다\n",
    "        for page in range(lastpage):\n",
    "            list_url = \"https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1={}&mid=sec&oid={}&date={}&page={}\".format(sids[sid], company_num, date, page)\n",
    "            list_html = requests.get(list_url, headers={\"User-Agent\" : \"Mozilla/5.0\"})\n",
    "            list_soup = BeautifulSoup(list_html.text, 'html.parser')\n",
    "\n",
    "            print(list_url)\n",
    "\n",
    "            # 뉴스 인덱스\n",
    "            elem_index = 0\n",
    "            # 각 뉴스 기사마다\n",
    "            for element in list_soup.select('div.list_body>ul a'):\n",
    "                # URL에 날짜를 줘도 다른 날짜의 기사도 같이 출력됨을 확인\n",
    "                # 따라서 수동으로 날짜 다를 경우 넘어가게 조치\n",
    "                article_date = list_soup.select('span.date')[elem_index].text\n",
    "                #if pd.to_datetime(article_date.split()[0]) != pd.to_datetime(date): elem_index += 1; continue\n",
    "\n",
    "                link = element['href']\n",
    "                title = element.text\n",
    "\n",
    "                for ele in titlelist:\n",
    "                    if ele.text[:10] in title:\n",
    "                        print(title, article_date)\n",
    "                        news['신문사'].append(company)\n",
    "                        news['제목'].append(title)\n",
    "                        news['link'].append(link)\n",
    "                        return news\n",
    "\n",
    "                elem_index += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=100&mid=sec&oid=422&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=101&mid=sec&oid=422&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=102&mid=sec&oid=422&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=103&mid=sec&oid=422&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=104&mid=sec&oid=422&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=105&mid=sec&oid=422&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=110&mid=sec&oid=422&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=100&mid=sec&oid=025&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=101&mid=sec&oid=025&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=102&mid=sec&oid=025&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=103&mid=sec&oid=025&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=104&mid=sec&oid=025&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=105&mid=sec&oid=025&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=110&mid=sec&oid=025&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=100&mid=sec&oid=023&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=101&mid=sec&oid=023&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=102&mid=sec&oid=023&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=103&mid=sec&oid=023&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=104&mid=sec&oid=023&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=105&mid=sec&oid=023&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=110&mid=sec&oid=023&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=100&mid=sec&oid=001&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=101&mid=sec&oid=001&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=102&mid=sec&oid=001&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=103&mid=sec&oid=001&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=104&mid=sec&oid=001&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=105&mid=sec&oid=001&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=110&mid=sec&oid=001&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=100&mid=sec&oid=308&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=101&mid=sec&oid=308&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=102&mid=sec&oid=308&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=103&mid=sec&oid=308&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=104&mid=sec&oid=308&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=105&mid=sec&oid=308&date=20201124&page=0\n",
      "https://news.naver.com/main/list.nhn?mode=LSD&listType=title&sid1=110&mid=sec&oid=308&date=20201124&page=0\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [신문사, 제목, link]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>신문사</th>\n      <th>제목</th>\n      <th>link</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ele in tmp:\n",
    "    startparse(ele[0])\n",
    "\n",
    "dataframe = pd.DataFrame(news)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "dataframe = pd.DataFrame(news)\n",
    "dataframe.to_csv('news.csv', encoding='utf-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}